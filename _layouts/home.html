<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{{ site.name }}'s CV</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        .announcement-item {
            transition: all 0.3s ease;
        }
        .announcement-item:hover {
            transform: translateX(5px);
        }
        .quick-link {
            transition: all 0.3s ease;
        }
        .quick-link:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(0,0,0,0.1);
        }
    </style>
</head>
<body class="bg-gray-50 min-h-screen">
    <!-- 顶部导航 -->
    <header class="bg-white shadow-sm border-b border-gray-200">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <div class="flex justify-between items-center h-16">
                <div class="flex items-center">
                    <i class="fas fa-user text-blue-600 text-2xl mr-3"></i>
		            <h1 class="text-xl font-semibold text-gray-900">{{ site.name }}'s CV</h1>
                </div>
                <div class="flex items-center space-x-4">
                    <span id="currentTime" class="text-sm text-gray-500"></span>
                    <a href="/">
                        <div class="flex items-center mb-1">
                            <i class="fas fa-home text-blue-600 text-2xl mr-3"></i>
                            <span class="text-xl font-semibold text-gray-700">Return Home</span>
                        </div>
                    </a>
                </div>
            </div>
        </div>
    </header>

    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
        <!-- 单列布局 -->
        <div class="space-y-8">
            <div class="bg-white rounded-lg shadow-sm p-6">
                <div>
                    <center>
                        <img src="{{ site.baseurl }}/assets/zeyu.jpg" alt="Avatar" class="w-[150px] h-[150px] rounded-full">
                        <h1 class="text-3xl font-bold">Zeyu Zhang</h1>
                        <p class="text-lg font-bold">
                            Email: <a href="mailto:zeyuzhang@meta.com" class="text-blue-600 underline">zeyuzhang@meta.com</a>
                            / <a href="mailto:qxc4fh@virginia.edu" class="text-blue-600 underline">qxc4fh@virginia.edu</a>
                            / <a href="mailto:{{ site.email }}" class="text-blue-600 underline">{{ site.email }}</a>
                        </p>
                    </center>
                </div>
            </div>

            <div class="bg-white rounded-lg shadow-sm p-6">
                <div>
                    <h3 class="text-2xl font-semibold text-gray-900 mb-4">
                        <i class="fas fa-circle-user text-blue-600 mr-2"></i>
                        INTRODUCTION
                    </h3>
                    <p>
                        I am a PhD student at the University of Virginia (UVA), focusing on systems for training, inference, and evaluation of Large Language Models (LLMs) and recommendation models. My research primarily centers on optimizing long-context models and improving the communication, computation, and memory efficiency of KV cache. I also work on mitigating straggler issues in large-scale Machine Learning (ML) training. Prior to my PhD, I worked on network communication optimization, including user-space networking stacks and Network Function Virtualization (NFV). Earlier in my career, I also conducted research in recommender systems and algorithms.
                    </p>
                </div>
            </div>

            <!-- 公告板 -->
            <div class="bg-white rounded-lg shadow-sm">
                <div class="pb-2 pt-6 px-6">
                    <h3 class="text-2xl font-semibold text-gray-900 mb-4">
                        <i class="fas fa-earth-americas text-blue-600 mr-2"></i>
                        EXPERIENCES
                    </h3>
                </div>
                <div class="pb-6 px-6">
                    <div id="announcementList" class="space-y-2">
                        <!-- 公告项目 -->
                        <div class="announcement-item bg-blue-50 border-l-4 border-blue-500 px-4 rounded-r-lg">
                            <div class="flex-1">
                                <h4 class="font-medium text-gray-900"><strong>Meta (Formerly Facebook), Sunnyvale, California, USA</strong> (06/2025-Now)</h4>
                                <p>
                                    <ul style="list-style-type: square; padding-left: 4ch;">
                                        <li><b>Research Scientist Intern (AI Systems Machine Learning)</b></li>
                                        <li>Working on systems for large language and recommendation models.</li>
                                    </ul>
                                </p>
                            </div>
                        </div>

                        <div class="announcement-item bg-green-50 border-l-4 border-green-500 px-4 rounded-r-lg">
                            <div class="flex-1">
                                <h4 class="font-medium text-gray-900"><strong>Harvard University, Boston, Massachusetts, USA</strong> (03/2024-08/2024)</h4>
                                <p>
                                    <ul style="list-style-type: square; padding-left: 4ch;">
                                        <li><b>Visiting Researcher</b></li>
                                        <li>Worked on systems for Large Language Models (LLMs). The main topic was LLM KV cache quantization, and we propsed homomorphic quantization for LLM KV cache to deal with communication, computation, and memory issues in disaggregated LLM serving.</li>
                                    </ul>
                                </p>
                            </div>
                        </div>

                        <div class="announcement-item bg-yellow-50 border-l-4 border-yellow-500 px-4 rounded-r-lg">
                            <div class="flex-1">
                                <h4 class="font-medium text-gray-900"><strong>Microsoft, Seattle, Washington, USA</strong> (05/2023-08/2023, 09/2024-12/2024)</h4>
                                <p>
                                    <ul style="list-style-type: square; padding-left: 4ch;">
                                        <li><b>Visiting Researcher</b></li>
                                        <li>Worked with DeepSpeed on LLM training, especially on long-context-model training.</li>
                                        <li>Worked with Azure on multi-modality model serving.</li>
                                    </ul>
                                </p>
                            </div>
                        </div>

                        <div class="announcement-item bg-cyan-50 border-l-4 border-cyan-500 px-4 rounded-r-lg">
                            <div class="flex-1">
                                <h4 class="font-medium text-gray-900"><strong>University of Virginia, Charlottesville, Virginia, USA</strong> (08/2021-Now)</h4>
                                <p>
                                    <ul style="list-style-type: square; padding-left: 4ch;">
                                        <li><b>PhD in Computer Science</b></li>
                                        <li>Working on systems for AI.</li>
                                        <li>Worked on LLM KV cache optimization and proposed ZACK to reduce KV cache size in the hidden size dimension, which is orthogonal to quantization and token eviction based methods. I also enhanced the self-attention kernel used for ZACK.</li>
                                        <li>Worked on long-context-model inference and proposed CSPS and PecSched for efficient long-context-model serving.</li>
                                        <li>Also worked on straggler problems in Machine Learning (ML) training.</li>
                                    </ul>
                                </p>
                            </div>
                        </div>

                        <div class="announcement-item bg-red-50 border-l-4 border-red-500 px-4 rounded-r-lg">
                            <div class="flex-1">
                                <h4 class="font-medium text-gray-900"><strong>Intel, Shanghai, China</strong> (06/2019-11/2019)</h4>
                                <p>
                                    <ul style="list-style-type: square; padding-left: 4ch;">
                                        <li><b>Intern in Network and Custom Logic Group (NCLG)</b></li>
                                        <li>Worked on user-space networking stack (collaborating with Cisco). I optimized NGINX based on open-source high-performance packet processing framework VPP to increase its throughput, achieve good scalability, reduce latency and reduce CPU usage.</li>
                                    </ul>
                                </p>
                            </div>
                        </div>

                        <div class="announcement-item bg-green-50 border-l-4 border-green-500 px-4 rounded-r-lg">
                            <div class="flex-1">
                                <h4 class="font-medium text-gray-900"><strong>Shanghai Jiao Tong University, Shanghai, China</strong> (09/2017-03/2020)</h4>
                                <p>
                                    <ul style="list-style-type: square; padding-left: 4ch;">
                                        <li><b>Master in Software Engineering</b></li>
                                        <li>Worked on network function virtualization (NFV).</li>
                                    </ul>
                                </p>
                            </div>
                        </div>

                        <div class="announcement-item bg-orange-50 border-l-4 border-orange-500 px-4 rounded-r-lg">
                            <div class="flex-1">
                                <h4 class="font-medium text-gray-900"><strong>Wuhan University, Wuhan, China</strong> (09/2013-06/2017)</h4>
                                <p>
                                    <ul style="list-style-type: square; padding-left: 4ch;">
                                        <li><b>Bachelor in Software Engineering</b></li>
                                        <li>Made identification of consumer groups in shopping malls and promoted the maximization of merchants' profits by predicting consumer groups' group behaviors.</li>
                                        <li>I designed an improved Apriori Algorithm that is able to efficiently conduct trajectory prediction in large shopping malls.</li>
                                    </ul>
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div id="research_papers" class="bg-white rounded-lg shadow-sm p-6">
                <div>
                    <h3 class="text-2xl font-semibold text-gray-900 mb-4">
                        <i class="fas fa-file-lines text-blue-600 mr-2"></i>
                        RESEARCH PAPERS
                    </h3>
                    <p>
                        <ul style="list-style-type: square; padding-left: 2ch;">
                            <li>Zeyu Zhang and Haiying Shen. PecSched: Preemptive and efficient cluster scheduling for LLM inference. arXiv: 2409.15104v2, 2025. [<a href="https://arxiv.org/abs/2409.15104v2" target="_blank" class="text-blue-600 underline">Link</a>]</li>
                            <li>Zeyu Zhang, Haiying Shen, Shay Vargaftik, Ran Ben Basat, Michael Mitzenmacher, and Minlan Yu. 2025. HACK: Homomorphic Acceleration via Compression of the Key-Value Cache for Disaggregated LLM Inference. In <i>ACM SIGCOMM 2025 Conference (SIGCOMM '25), September 8-11, 2025, Coimbra, Portugal</i>. ACM, New York, NY, USA, 3 pages. <a href="https://doi.org/10.1145/3718958.3750481" target="_blank" class="text-blue-600 underline">https://doi.org/10.1145/3718958.3750481</a> [<a href="{{ site.baseurl }}/assets/hack_short_sigcomm_25.pdf" class="text-blue-600 underline">Link</a>]</li>
                            <li>Zeyu Zhang and Haiying Shen. FDC: Fast KV dimensionality compression for efficient LLM inference. arXiv: 2408.04107v3, 2025. [<a href="https://arxiv.org/abs/2408.04107v3" target="_blank" class="text-blue-600 underline">Link</a>]</li>
                            <li>Suraiya Tairin, Zeyu Zhang, and Haiying Shen. Revisiting the straggling problem in GPU-based distributed deep learning training. In 2025 34th International Conference on Computer Communications and Networks (ICCCN), pages 1-9, 2025.</li>
                            <li>Haoran Qiu, Anish Biswas, Zihan Zhao, Jayashree Mohan, Alind Khare, Esha Choukse, Íñigo Goiri, Zeyu Zhang, Haiying Shen, Chetan Bansal, Ramachandran Ramjee, and Rodrigo Fonseca. ModServe: Scalable and resource-efficient large multimodal model serving. arXiv: 2502.00937v2, 2025. [<a href="https://arxiv.org/abs/2502.00937v2" target="_blank" class="text-blue-600 underline">Link</a>]</li>
                            <li>Haiying Shen and Zeyu Zhang. Deep learning training job scheduling for proactive straggler reduction. In 2025 IEEE 25th International Symposium on Cluster, Cloud and Internet Computing (CCGrid), pages 1-12, 2025.</li>
                            <li>Zeyu Zhang, Haiying Shen, Shay Vargaftik, Ran Ben Basat, Michael Mitzenmacher, and Minlan Yu. HACK: Homomorphic acceleration via compression of the key-value cache for disaggregated LLM inference. arXiv: 2502.03589v1, 2025. [<a href="https://arxiv.org/abs/2502.03589v1" target="_blank" class="text-blue-600 underline">Link</a>]</li>
                            <li>Zeyu Zhang and Haiying Shen. ZACK: Zero-overhead LLM inference acceleration via dimensionality compression of the key-value cache. arXiv: 2408.04107v2, 2024. [<a href="https://arxiv.org/abs/2408.04107v2" target="_blank" class="text-blue-600 underline">Link</a>]</li>
                            <li>Zeyu Zhang and Haiying Shen. CSPS: A communication-efficient sequence-parallelism based serving system for transformer based models with long prompts. arXiv: 2409.15104v1, 2024. [<a href="https://arxiv.org/abs/2409.15104v1" target="_blank" class="text-blue-600 underline">Link</a>]</li>
                            <li>Suraiya Tairin, Haiying Shen, and Zeyu Zhang. Embracing uncertainty for equity in resource allocation in ML training. In Proceedings of the 52nd International Conference on Parallel Processing, ICPP '23, page 423-432, New York, NY, USA, 2023. Association for Computing Machinery.</li>
                            <li>Zeyu Zhang and Weiping Zhu. Location and motion prediction of consumers in a large shopping mall. In 2017 Fifth International Conference on Advanced Cloud and Big Data (CBD), pages 250-255, 2017.</li>
                        </ul>
                    </p>
                </div>
            </div>

            <div class="bg-white rounded-lg shadow-sm p-6">
                <div>
                    <h3 class="text-2xl font-semibold text-gray-900 mb-4">
                        <i class="fas fa-book-open text-blue-600 mr-2"></i>
                        PATENTS
                    </h3>
                    <p>
                        <ul style="list-style-type: square; padding-left: 2ch;">
                            <li>A Network Request Processing System and Method (Jian Li, Zeyu Zhang, Haibing Guan) (Chinese Patent Number: 202010059255.0)</li>
                        </ul>
                    </p>
                </div>
            </div>
        </div>
    </div>

    <script>
        // 更新时间显示
        function updateTime() {
            const now = new Date();
            const timeString = now.toLocaleString('en', {
                year: 'numeric',
                month: '2-digit',
                day: '2-digit',
                hour: '2-digit',
                minute: '2-digit',
                second: '2-digit'
            });
            document.getElementById('currentTime').textContent = timeString;
        }

        // 初始化
        updateTime();
        setInterval(updateTime, 1000);
    </script>
</body>
</html>
